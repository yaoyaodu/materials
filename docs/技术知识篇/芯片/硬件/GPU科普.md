# GPU科普

来源：慧博智能策略终端   20210917-东吴证券-计算机应用行业：GPU的那些事儿，关于GPU的科普

半导体行业专题研究：从英伟达看国产GPU发展机遇与挑战：https://zhuanlan.zhihu.com/p/565320398 

## GPU概念

GPU 最初是为了更好的做图形处理而专门设计的**微处理器**。GPU 的全称是Graphics Processing Unit，图形处理单元。它最初的功能主要用于绘制图像和处理图元数据的特定芯片，后来增加了许多其他功能。

**GPU 是显卡最核心的部件**。显卡（显示接口卡），负责把CPU（Central Processing Unit，中央处理器）送来的影像数据（显示信号）处理成显示器可以认知的格式（一般电器信号），再送到显示屏上形成影像。

**GPU 就是显卡的核心，决定如何处理屏幕上的每个像素点**。**显卡里除了GPU 外，还有散热器、通讯元件、与主板和显示器连接的各类插槽。**



## GPU 的工作原理

GPU 将3D 图形映射到相应的像素点上，对每个像素进行计算，确定最终颜色并完成输出。其中工作内容包括：

1）**顶点处理**，GPU 读取描述3D 图形外观的顶点数据，并根据顶点数据**确定3D 图形的形状及位置，建立3D 图形骨架。**

2）**光栅化**，显示器实际显示的图像是由像素点组成的。**把一个矢量图形转换为一系列像素点的过程就称为光栅化。**例如，把一条线段转化为阶梯状的连续像素点。

3）**纹理贴图**，顶点单元生成的多边形只构成了3D 物体的外轮廓，**纹理贴图将多边形的表面贴上相应的图片，从而生成完整的3D 图形**。

4）**最终输出**，由**ROP（光栅化引擎）最终完成像素的输出**，1 帧图像渲染完毕后，被送到显存帧缓冲区。

GPU 比CPU 擅长并行计算。正如上段所说，一个3D 图形最终会被分解为许多个像素点来计算，如果要渲染速度快，这就要求GPU 的硬件结构是满足同时进行大量的简单计算的，这个需求导致了GPU 与CPU 的硬件架构不同。

* 从芯片设计思路看，CPU是以低延迟为导向的计算单元，通常由专为串行处理而优化的几个核心组成，
* GPU 是以吞吐量为导向的计算单元，由数以千计的更小、更高效的核心组成，专为并行多任务设计。

微架构的不同最终导致**CPU 中大部分的晶体管用于构建控制电路和缓存**，**只有少部分的晶体管完成实际的运算工作**，功能模块很多，擅长分支预测等复杂操作。

GPU的**流处理器（承担简单计算任务）和显存控制器占据了绝大部分晶体管**，而**控制器相对简单**，擅长对大量数据进行简单操作，拥有远胜于CPU 的强大浮点计算能力，从而更擅长并行计算，比如图像处理计算，物理仿真，深度学习等。



## GPU 发展史：从固定功能到统一渲染架构

### 2000 年之前：固定功能架构时代

1. **一切的开端，计算图形学。**1962 年，麻省理工大学的博士伊凡·苏泽尔的论文以及他的画板程序奠定了计算机图形学的基础。**1962-1984 年，这一阶段，没有专门的图形处理硬件，图形处理任务都由CPU 完成。**
2. **萌芽时期，专门的图形处理硬件出现。**随着计算机的发展，图像处理需求逐步增加。1984 年，美国SGI 公司推出了面向专业领域的高端图形工作站。1984-1995 年，SGI 又不断研发出了一系列性能更好的图形工作站。但由于价格昂贵，无法面向消费级市场。**在消费级领域，还没有专门的图形处理硬件**。
3. **茁壮成长，消费级显卡出现，图形处理硬件发展加速。**1995 年，3DFX 公司发布一款消费级3D 显卡Voodoo。此时，图形显示硬件赛道已经开始变得火热，AMD、ATI（2006 年被AMD 收购）、NVIDIA 都开始推出自己的显卡产品。**CPU 得以摆脱部分图形处理任务，但是顶点变换等任务仍需CPU 完成**。
4. **GPU 时代来临。**1999 年**NVIDIA 发布的GeForce 256 图形芯片，首次引入GPU 的概念，GPU 时代来临**。GeForce 256 采用了“T&L”硬件，立方环境材质贴图和顶点混合等先进技术。

此阶段为固定功能架构时代。在这一时期，各硬件单元形成一条图形处理流水线，每个流水级功能固定，硬化了一些给定的函数，多条像素流水线对各自的输入数据进行相同的操作，**不可对硬件进行编程**。

### 2001-2005 年：分离渲染架构时代

**GPU 具备了可编程属性。**GPU 用顶点渲染器替换了变换与光照相关的固定单元、用可编程的像素渲染器替换了纹理采样与混合相关的固定单元。2003 年，NVIDIA 和ATI 发布的新产品都同时具备了可编程顶点处理和可编程像素处理器，具备了良好的编程性。

**顶点渲染器和像素渲染器在硬件上相互分离**。顶点渲染器和像素渲染器**在物理上是两部分硬件，不可相互通用**，这个时期叫做分离渲染架构时代。

### 2006 年至今：统一渲染架构时代

**GPU 开始采用统一渲染架构。**传统的GPU 采用分离架构，**顶点处理（由Vertex Shader 硬件单元完成）和像素处理（由Pixel Shader 硬件单元完成）**在硬件上相互分离，于是，当GPU 核心设计完成时，PS 和VS 的数量便确定下来了。但是**不同的游戏对于两者处理量需求是不同的，这种固定比例的PS VS 设计显然不够灵活。**为了解决这个问题，DirectX10 规范中提出了统一渲染架构。**在统一渲染架构中，PS 单元和VS 单元都被通用的US 单元所取代，NVIDIA 的产品中称其为SP（Streaming Processer），即流处理器，**这种US 单元既可以处理顶点数据，又可以处理像素数据，因而GPU 可以根据实际处理需求进行灵活的分配，这样便有效避免了传统分离式架构中VS 和PS 工作量不均的情况。

**GPGPU 出现，功能从图形显示拓向高性能计算。**统一渲染架构的采用，GPU 硬件单元更加灵活，进一步增强了GPU 的可编程属性。大数据时代的到来，GPU 并行计算的能力被进一步发掘，GPU 被用于图形处理之外的其他领域，如人工智能、挖矿等，**GPGPU（通用GPU，指利用处理图形任务的GPU 来处理原本由中央处理器处理的通用计算任务）的概念开始出现。**GPU 厂商们洞察到了这一商机，也开始从硬件和软件上提供对GPGPU 的专门支持。NVIDIA 毫无争议是这一商机的首先发现者与推进者，伴随着Tesla 系列GPU，**2006 年发布了CUDA 软件平台，来支持GPU 用于非图形处理的其他用途**。AMD 也不甘示弱，针对FireStream 系列GPU，**2016 年发布了ROCm 软件平台**。



## 从NVIDIA Fermi 架构看GPU 微观硬件架构组成

**进入统一渲染架构时代后，GPU 架构快速发展。**NVIDIA 的GPU 架构历经多次变革，约2 年更新一次。NVIDIA 为了纪念物理学家，把每代GPU 架构都用物理学家名字来命名：特斯拉（Tesla）、费米（Fermi）、开普勒（Kepler）、麦克斯韦（Maxwell）、帕斯卡（Pascal）、伏特（Volta）、安培（Ampere）。

2010 年发布的Fermi 是第一个完整的GPU 计算架构。第一个基于Fermi 架构的GPU，使用30 亿个晶体管实现，**共计512 个CUDA 内核（绿色小块，负责数学运算）**。

这512 个CUDA 内核被组织成**16 个SM（流处理器**，Streaming Multiprocessor），**每个SM 是一个垂直的矩形条带(红框)，**分别位于一个普通的L2cache 周围，**每个SM 有32个CUDA 内核**。

图6：Fermi 架构示意图

![image-20211101105548965](C:\Users\dongdong li\materials\docs\技术知识篇\芯片\硬件\GPU科普\image-20211101105548965.png)



GPU 中包含多个GPC。GPC 可以被认为是一个独立的GPU。整个GPU 有多个GPC(图形处理集群)，**单个GPC 包含1 个光栅引擎(Raster Engine)，4 个SM（流式多处理器），它们其中有很多连接。**所有从Fermi 开始的NVIDIA GPU，都有GPC。**主机接口(Host Interface )通过PCI-Express 将GPU 连接到CPU。Giga Thread 全局调度器**将线程块分发给SM 线程调度器。

图7：Fermi 架构图

![image-20211101110413037](C:\Users\dongdong li\materials\docs\技术知识篇\芯片\硬件\GPU科普\image-20211101110413037.png)

GPC 的主要组成部分SM（Streaming Multiprocessors）。单个GPC 包含1 个光栅引擎(Raster Engine)，4 个SM。GPU 硬件的并行性就是由SM 决定的。**每个SM 具有32 个CUDA 内核（绿色方块），每个CUDA 内核都有一个完全流水线化的整数算术逻辑单元(ALU)和浮点单元(FPU)，其负责计算。**

这些Core 由Warp Scheduler 驱动，Warp Scheduler 管理一组线程束（Warp）并将要执行的指令移交给Dispatch Unites，Dispatch Unites 再通过寄存器（Register File）将任务分给每个Core。LD/ST（Load/Store）模块来加载和存储数据，SFU（Special Function Units）执行特殊数学运算（sin、cos、log 等）。

图8：SM 内部结构

![image-20211101110601759](C:\Users\dongdong li\materials\docs\技术知识篇\芯片\硬件\GPU科普\image-20211101110601759.png)



图9：CUDA Core 内部组成

![image-20211101110631581](C:\Users\dongdong li\materials\docs\技术知识篇\芯片\硬件\GPU科普\image-20211101110631581.png)



## GPU 重要参数解释及GPU 性能比较

### GPU重要参数解释

- **显存，全称显示内存，暂时储存显示芯片要处理的数据和处理完毕的数据。**图形**核心的性能愈强，需要的显存也就越多**。显存类型从原来的**容量不大的SDR，发展到DDR、SDRAM、DDR3、DDR4 等**。从Pascal 架构开始，NVIDIA 已经开始提供HBM2 类型的显存，最新针对专业计算的Tesla A100 采用HBM2，显存容量可达40GB，为游戏设计的RTX 8080 Ti 采用DDR6，显存容量也可达12GB。**显存主要由传统的内存制造商提供，比如三星、现代、Kingston 等。**
- **显存位宽，指一个时钟周期内能传输数据的位数（bit）。**显存**位宽位数越大则瞬间所能传输的数据量越大**，这是显存的重要参数之一。显存位宽越高，性能越好价格也就越高，因此**512 位宽的显存更多应用于高端显卡**。
- **显存频率**指**显存在显卡上工作时的频率**，以MHz（兆赫兹）为单位。显存频率一定程度上反应着**该显存存取的速度**。显存频率随着显存的类型、性能的不同而不同，**DDR、SDRAM 显存则能提供较高的显存频率，因此是采用最为广泛的显存类型**。近年来，GPU显存频率已经从百级提升到万级，GTX 1080 Ti 的显存频率已经高达10000MHz。
- **显存带宽**，指**显示芯片与显存之间的数据传输速率，**单位是字节/秒。显卡的显存是由一块块的显存芯片构成的，显存总位宽同样也是由显存颗粒的位宽组成，显存带宽＝显存频率×显存位宽/8。显存带宽是决定显卡性能和速度最重要的因素之一。

- **制作工艺，指的是晶体管与晶体管之间的距离**，单位是纳米。制作工艺越小说明**集成度越高，功耗越小，性能越好**。目前NVIDIA 最先进的Tesla 采用7nm 制程，GTX1080 Ti 采用16nm 制程。
- **像素填充速率，指GPU 一秒钟内能处理多少个像素**，单位是GPixel/S（每秒十亿像素），或MPixel/S（每秒百万像素）。像素填充速率是较好**衡量GPU 图像显示功能**的整体指标，说明了**显卡能以多快的速度对图像进行光栅化处理**。显卡的硬件指标对其速度具有直接影响。
- **纹理填充率，指对多边形图像进行纹理贴图、实现3D 效果的速度**，和像素填充率类似，单位是GTexels/S 或MTexels/S。游戏采用了多纹理贴图的方式，使画面具有更好的光影效果。**像素填充率和纹理填充率反映的是GPU 的性能，而显存带宽则体现了显存的性能。**
- 功率，集显依靠CPU 的主板连接提供电源，但独显性能较强，需要单独接电源。如RTX 3080 Ti 功率为750w。
- 总线接口，**显示卡要插在主板上才能与主板互相交换数据，现在主流接口为PCLe（PCI-Express）**。接口提供数据流量带宽，目前主流采用PCLe4.0 版本，16 个通道。
- **Directx 支持，简称DX，是一种应用程序接口（API）**。DX 由微软编写，由很多的API 组成，包括显示、声音、输入和网络。DirectX 11 还支持高质量实时渲染和预渲染场景，目前DX 已发展到Directx 12 版本，提高了多线程效率，可以充分发挥多线程硬件的潜力。
- **CUDA Core 和Tensor Core，为GPU 提供计算能力的硬件单元**。**CUDA core 也叫Streaming Processor（SP），是单精度，组成SM 的重要部分**。Tensor Core 已发展到第三代，Tensor Core 大幅减少了深度学习需要的时间。**Core 的数量越多，并行运算的线程越大，计算的峰值越高。**





### 如何去对比GPU

GPU 性能最直接的体现就是**画图的速度**，对应的指标就是**像素填充率和纹理填充率**。

其他一些指标，也可以间接的反应GPU 的性能，如**CUDA Core、Tensor Core 的数量、核心频率（显示核心的工作频率）、显存位宽、显存频率**等。这些**值越大，往往意味着性能更强**。



# GPU 投资机会及相关标的

人工智能时代来临，GPU 应用领域不断扩展，市场需求愈加旺盛。自统一渲染架构提出以来，GPU 技术快速发展，新兴应用场景的不断涌现，如车载，摄像头等，有望进一步催生市场需求，打开更广阔的市场空间。在此背景下，我们预计2027 年中国独立GPU 市场规模有望超过346 亿美元，推荐GPU 相关标的景嘉微，关注中科曙光、航锦科技等。

