# 软件栈

核心概念：

* 框架Framework
* 抽象体系：**AI软件栈**的本质是基于某款AI硬件，用于**衔接上层AI应用的抽象体系**。
* **软件抽象**：因为不可能把**底层硬件**直接暴露给**上层具体的AI应用**，那样**太影响生产效率**，所以引入了**一层又一层的AI软件抽象**，构成了AI软件栈。
* 在这个软件栈层次图里，**每个building block其实都试图提供一种抽象**。
* CUDA核心：**CUDA核心数量决定了GPU并行处理的能力**，在深度学习、机器学习等**并行计算**类业务下，CUDA核心多意味着性能好一些。
* 软件栈：**work together to support the execution of an application**
* 软件栈组成部分：
  * **operating system**
  * architectural layers
  * protocols
  * runtime environments
  * databases and function calls

* The lower-level components in the hierarchy **interact with hardware**.
* The higher-level components in the hierarchy **perform specific tasks and services for the end user**.

## 软件栈

A software stack is **a collection of independent components** that **work together to support the execution of an application**. The components, which may include an **operating system, architectural layers, protocols, runtime environments, databases and function calls**, are stacked one on top of each other in a hierarchy.     

Typically, **the lower-level components in the hierarchy interact with hardware**, while **the higher-level components in the hierarchy perform specific tasks and services for the end user**. Components communicate directly with the application through a series of complex instructions that traverse the stack.

## Framework

Framework层为**开发应用程序提供了非常多的API**，我们通过调用特殊的API构造我们的APP，满足我们业务上的需求。

Framework其实可以简单的理解为一些**API的库房**，android开发人员**将一些基本功能实现，通过接口提供给上层调用**，可以重复的调用Framework层才真正是Java语言实现的层，在这层里定义的API都是用Java语言编写。但是又因为它包含了JNI的方法，JNI用C/C++编写接口，根据函数表查询调用核心库层里的底层方法，最终访问到Linux内核。

**Android的Framework是直接应用之下的一层，叫做应用程序框架层**。这一层是**核心应用程序所使用的API框架，为应用层提供各种API**，**提供各种组件和服务**来支持我们的Android开发，包括ActivityManager,WindowManager,ViewSystem等。

Android系统的构成如下，从上到下依次是：

-Application应用层

-Framework框架层

-LIbrary系统库层

-Linux内核层

Android Framework的三大核心功能：
1、View.java:View工作原理，实现包括绘制view、处理触摸、按键事件等。
2、ActivityManagerService.java:Ams 管理所有应用程序的Activity等。
3、WindowManagerService.java:Wms 为所有应用程序分配窗口，并管理这些窗口。





## AMD ROCm

AMD ROCm is the first open-source software development platform for HPC/Hyperscale-class GPU computing. AMD ROCm brings the UNIX philosophy of choice, minimalism and modular software development to GPU computing.

Since the ROCm ecosystem is comprised of **open technologies**: **frameworks (Tensorflow / PyTorch), libraries (MIOpen / Blas / RCCL), programming model (HIP), inter-connect (OCD) and up streamed Linux® Kernel support** – the platform is continually optimized for performance and extensibility. Tools, guidance and insights are shared freely across the **ROCm GitHub community and forums**.

Note: The AMD ROCm™ open software platform is a compute stack for headless system deployments. GUI-based software applications are currently not supported.

**Complete exascale solution for ML/HPC:**

- Applications: HPC apps, ML frameworks
- **Cluster deployment: Singularity, SLURM, Docker, Kubernates**
- Tools: Debugger, Profiler, Tracer, System Valid. System Mgmt.
- Portability Frameworks: Kokkos, Magma, GridTools, ONNX
- **Math libraries**: RNC, FFT, Sparse, BLAS, Eigen, MIOpen
- Scale-out **communication libraries**: OpenMPI, UCX, MPICH, RCCL
- **Programmming Models**: OpenMP, HIP, OpenCL
- Processors: CPU + GPU

![image-20220816091259865](C:\Users\杜瑶瑶\AppData\Roaming\Typora\typora-user-images\image-20220816091259865.png)



## AI软件栈

**AI软件栈**的本质是基于某款AI硬件，用于**衔接上层AI应用的抽象体系**。

因为我们不可能把底层硬件直接暴露给上层具体的AI应用，那样太影响生产效率，所以引入了一层又一层的AI软件抽象，构成了AI软件栈。以NV的软件栈为例。

- 为了让上层应用在**不需要touch到SASS 汇编的情况下享受到开发NV平台高性能程序的福利**，有了**CUDA**。
- 为了让**上层应用**在**不需要关注底层CUDA优化细节**的情况下享受到**高性能GEMM库**的红利，有了**cuBLAS**。
- 为了让**AI specific的计算需求**在**不需要关注底层实现细节**的情况下有效发挥NV GPU的性能，有了**cuDNN**(对**convolution，attention，BN**等**常见AI算子的支持**)。
- 为了让**AI布署**需求不需要关注太多底层实现细节即可有效发挥NV GPU的性能，于是有了**TensorRT**。更进一步，为了**简化TensorRT集成在推理布署服务系统里的overhead**，诞生了**Triton Inference Server**。
- 为了让**AI训练**需求在不需要关注**底层硬件拓扑互联**细节的情况下有效发挥**互联性能**，于是有了**NCCL**。先是1.0的单机多卡，然后是2.0的单机多卡支持。
- 为了简化NV GPU上**超大规模语言模型类的训练负担**，于是有了Megatron-LM。
- 为了**给上层AI应用提供更大的灵活性来根据上层需求来定制计算优化策略**，于是有了**CUTLASS**(cuDNN V8也有一些性质相似的尝试，比如fusion)。
- 为了让AI业务层获得**开箱即用的AI框架**使用体验，于是有了NGC里的TensorFlow/PyTorch等一众AI框架的NV优化加持。

可以把NV的软件栈抽象层次做一个梳理展示如下：

* Megatron-LM, Triton

* NV TensorFlow, PyTorch, TensorRT
* NCCL, CUTLASS, cuDNN, cuBLAS
* CUDA
* SASS
* NV GPU

说明：

The NVIDIA CUDA Deep Neural Network (**cuDNN**) library is a **GPU-accelerated library of primitives for deep neural networks.** 

cuDNN **provides highly tuned implementations for standard routines** such as forward and backward convolution, pooling, normalization, and activation layers. 

Deep learning researchers and framework developers worldwide rely on cuDNN for high-performance GPU acceleration.



在这个软件栈层次图里，**每个building block其实都试图提供一种抽象**。比如：

- Megatron-LM想提供的是**针对大模型训练的抽象**。 NV TensorFlow和NV PyTorch是**AI框架的抽象**。
- Triton是**服务布署系统的抽象**。TensorRT是**推理优化工具的抽象**。
- 这些抽象模块之间又存在分层。比如**Megatron-LM依赖于NV-PyTorch的AI框架优化能力**。**Triton会用到TensorRT暴露的调用接口**。

同时，这里面几乎所有的抽象都存在**leaky abstraction**的问题(对应于图片里的红线)，在Raja Koduri 在Hotchips20的[《No Transistor Left Behind》](https://link.zhihu.com/?target=https%3A//www.intel.com/content/www/us/en/newsroom/news/raja-koduri-keynote-hot-chips-2020.html)的keynote里有一页形象的slides也emphasize了这个问题(图片里的洞表示了leaky abstraction的存在)。

[再谈AI软件栈 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/393041071)

![image-20220815113707619](C:\Users\杜瑶瑶\AppData\Roaming\Typora\typora-user-images\image-20220815113707619.png)